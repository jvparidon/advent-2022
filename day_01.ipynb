{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c84519ee-1744-4eee-9738-970a314b76bc",
   "metadata": {},
   "source": [
    "# Advent of Code, day 1\n",
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa95eb8-5c34-40bf-b6ae-8a36980b75a9",
   "metadata": {},
   "source": [
    "Data is in a text file named `day_01.txt` in the data dir. A cursory look at the file shows blocks of numbers are separated by double line break, so we can read and split on that separator before doing anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c680838c-b5d2-4b06-bc6c-c1b8c4c3732f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2832\\n2108\\n3082\\n4328\\n6843\\n5121\\n2869\\n1366\\n2358\\n1680\\n4980\\n1161',\n",
       " '8026\\n2154\\n4242\\n1023\\n2744\\n3162\\n4093\\n1150\\n5397\\n2738\\n5657',\n",
       " '10954\\n11208\\n8034\\n1636\\n9430\\n9421\\n5025']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/day_01.txt', 'r') as infile:\n",
    "    blocks = infile.read().split('\\n\\n') \n",
    "blocks[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189df8da-ff67-4b50-b148-8cabff025fa7",
   "metadata": {},
   "source": [
    "Alright, now we have each block as a list item, but they're still strings with line breaks as delimiters between the integers.\n",
    "\n",
    "Let's try a few different methods to split, cast to int, sum, and take the maximum of these blocks of numbers. We'll use the `%timeit` magic to see which method is fastest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129cdc99-e34d-4767-b761-704bac8d7e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217 µs ± 9.22 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67622"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all maps, using an anonymous function for mapping the split blocks to integers\n",
    "%timeit max(map(sum, tuple(map(lambda block: map(int, block.split()), blocks))))\n",
    "max(map(sum, tuple(map(lambda block: map(int, block.split()), blocks))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35b1a853-3729-4acb-ae58-d2a6306760d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209 µs ± 9.79 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# outer map, but using a tuple comprehension to cast the split blocks to integers\n",
    "%timeit max(map(sum, (map(int, block.split()) for block in blocks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84396cc9-5837-48fe-8c36-22066f05e22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259 µs ± 2.38 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# nested tuple comprehensions\n",
    "%timeit max((sum((int(num) for num in block.split())) for block in blocks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f302622-63d5-4ab1-aebc-9ed12f828019",
   "metadata": {},
   "source": [
    "Looks like a mix of map and tuple comprehension is actually fastest, potentially because the lambda in the all-map solution introduces some additional overhead that the map/tuple comprehension combination does not.\n",
    "\n",
    "The nested tuple comprehension solution is slowest, perhaps because allocation isn't optimal when using lists of varying lengths?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2166756a-d17e-48c6-a43c-87825a8d2376",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64cb3972-f8df-43f9-98f3-e9347bf2fa5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222 µs ± 16.5 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "201491"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting\n",
    "%timeit sum(sorted(tuple(map(sum, (map(int, block.split()) for block in blocks))))[-3:])\n",
    "sum(sorted(tuple(map(sum, (map(int, block.split()) for block in blocks))))[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae16c28e-85b0-48d8-9473-ccfbae5a2ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395 µs ± 118 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit import numpy as np\n",
    "# numpy argmax\n",
    "arr = np.array(tuple(map(sum, (map(int, block.split()) for block in blocks))))\n",
    "arr[np.argpartition(arr, -3)[-3:]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98255909-acfe-4146-be58-94a720010f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238 µs ± 19.9 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit import numpy as np\n",
    "# numpy sort\n",
    "np.sort(tuple(map(sum, (map(int, block.split()) for block in blocks))))[-3:].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c343704-514a-45e4-9263-ddb87a5c9bc2",
   "metadata": {},
   "source": [
    "The numpy argmax has better time complexity, in theory, than the numpy sort, but the additional variable assignment that we need to do probably introduces a bit of extra overhead, making it a wash for this comparatively small array.\n",
    "\n",
    "The base Python sort is still the fastest option.\n",
    "\n",
    "For both Part 1 and Part 2 it's possible that a highly optimized solution for this specific problem (e.g. iterating over the blocks and storing the three highest values) is faster for (very) large datasets, but I'm not really interested in that kind of optimization, mostly because it tends to produce fragile algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd61be61-5998-40c2-8e59-48e57db62a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
